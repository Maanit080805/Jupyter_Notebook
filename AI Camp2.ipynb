{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have successfully imported requests version 2.24.0\n",
      "You have successfully imported beautifulsoup version 4.9.3\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "print (\"You have successfully imported requests version \"+requests.__version__)\n",
    "print (\"You have successfully imported beautifulsoup version \"+bs4.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = 'https://en.wikipedia.org/wiki/Jupiter'\n",
    "r = requests.get(base_url)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(r.text,'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "Formation and migration\n",
      "Physical characteristics\n",
      "Orbit and rotation\n",
      "Observation\n",
      "History of research and exploration\n",
      "Moons\n",
      "Interaction with the Solar System\n",
      "Mythology\n",
      "See also\n",
      "Notes\n",
      "References\n",
      "External links\n",
      "Navigation menu\n"
     ]
    }
   ],
   "source": [
    "headers = []\n",
    "for url in soup.findAll(\"h2\"):\n",
    "    headers.append(url.text)\n",
    "    print(url.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Contents', 'Formation and migration', 'Physical characteristics', 'Orbit and rotation', 'Observation', 'History of research and exploration', 'Moons', 'Interaction with the Solar System', 'Mythology', 'See also', 'Notes', 'References', 'External links', 'Navigation menu']\n"
     ]
    }
   ],
   "source": [
    "i = len(headers) - 1\n",
    "counter = 0\n",
    "while counter <= i:\n",
    "    if headers[counter].startswith('\\n'):\n",
    "        headers.pop(counter) #it will pop out \\n\n",
    "        counter -= 1\n",
    "    counter += 1\n",
    "    i = len(headers) -1\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_next_sibling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-90baa0a8aa26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html5lib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdeet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Search for div tags of class 'entry-content content'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpara\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_next_sibling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Within these tags, find all p tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_next_sibling'"
     ]
    }
   ],
   "source": [
    "r = requests.get(base_url)\n",
    "soup = bs4.BeautifulSoup(r.text,'html5lib')\n",
    "deet = soup.find('h3', text = headers[0]) # Search for div tags of class 'entry-content content'\n",
    "para = deet.find_next_sibling('p') # Within these tags, find all p tags\n",
    "print(para.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(base_url)\n",
    "all_para = \"\"\n",
    "soup = bs4.BeautifulSoup(r.text,'html5lib')\n",
    "for iteri in range(len(headers)):\n",
    "    deet = soup.find('h3', text = headers[iteri]) # Search for div tags of class 'entry-content content'\n",
    "    for para in deet.find_next_siblings(): # Within these tags, find all p tags\n",
    "        if para.name == \"h2\" or para.name == \"h3\":\n",
    "            break\n",
    "        elif para.name == \"p\":\n",
    "            all_para += para.get_text()\n",
    "            all_para += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./wiki.txt', 'wb') as file_handler:\n",
    "        file_handler.write(all_para.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "url = 'https://sl2files.sustainablelivinglab.org/DatasetSocialMedia-Disaster-tweets-DFE.csv'\n",
    "csv = urllib.request.urlopen(url).read()\n",
    "with open('./socialmedia-disaster-tweets-DFE.csv', 'wb') as fx:\n",
    "    fx.write(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "print (\"You have successfully imported pandas version \"+pd.__version__)\n",
    "print (\"You have successfully imported nltk version \"+nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv file that contains the tweets on natural disasters into a pandas dataframe\n",
    "df_raw = pd.read_csv('socialmedia-disaster-tweets-DFE.csv',encoding='ISO-8859-1')\n",
    "\n",
    "print (\"You have successfully loaded your csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['_unit_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_raw['text'].sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
